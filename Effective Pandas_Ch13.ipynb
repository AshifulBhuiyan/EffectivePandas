{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dates in the Index\n",
    "- dates in index is nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_27904/3771879567.py:4: DtypeWarning: Columns (68,70,71,72,73,74,76,79) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df=pd.read_csv(url)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "url = 'https://github.com/mattharrison/datasets/raw/master/data/vehicles.csv.zip'\n",
    "df=pd.read_csv(url)\n",
    "city_mpg = df.city08\n",
    "highway_mpg = df.highway08\n",
    "make = df.make\n",
    "url = 'https://github.com/mattharrison/datasets/raw/master/data/alta-noaa-1980-2019.csv'\n",
    "alta_df = pd.read_csv(url)\n",
    "dates = pd.to_datetime(alta_df.DATE)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-01    2.0\n",
       "1980-01-02    3.0\n",
       "1980-01-03    1.0\n",
       "1980-01-04    0.0\n",
       "1980-01-05    0.0\n",
       "             ... \n",
       "2019-09-03    0.0\n",
       "2019-09-04    0.0\n",
       "2019-09-05    0.0\n",
       "2019-09-06    0.0\n",
       "2019-09-07    0.0\n",
       "Name: SNOW, Length: 14160, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow = (alta_df.SNOW.rename(dates)\n",
    "        )\n",
    "snow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 Finding Missing Data\n",
    "Looking for missing data methods:\n",
    "\n",
    "- `.any` : checks for missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985-07-30   NaN\n",
       "1985-09-12   NaN\n",
       "1985-09-19   NaN\n",
       "1986-02-07   NaN\n",
       "1986-06-26   NaN\n",
       "              ..\n",
       "2017-04-26   NaN\n",
       "2017-09-20   NaN\n",
       "2017-10-02   NaN\n",
       "2017-12-23   NaN\n",
       "2018-12-03   NaN\n",
       "Name: SNOW, Length: 365, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checks for where missing data is:\n",
    "snow[snow.isna()]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With date index, can provide partial date strings to the `.loc` index attribute.\n",
    "Allows us to inspect around missing data and see if it gives any insight into with its missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985-09-01    0.0\n",
       "1985-09-02    0.0\n",
       "1985-09-03    0.0\n",
       "1985-09-04    0.0\n",
       "1985-09-05    0.0\n",
       "1985-09-06    0.0\n",
       "1985-09-07    0.0\n",
       "1985-09-08    0.0\n",
       "1985-09-09    0.0\n",
       "1985-09-10    0.0\n",
       "1985-09-11    0.0\n",
       "1985-09-12    NaN\n",
       "1985-09-13    0.0\n",
       "1985-09-14    0.0\n",
       "1985-09-15    0.0\n",
       "1985-09-16    0.0\n",
       "1985-09-17    0.0\n",
       "1985-09-18    0.0\n",
       "1985-09-19    NaN\n",
       "1985-09-20    0.0\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.loc['1985-09':'1985-09-20']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Filling in Missing Data\n",
    "Multiple ways of doing this, can use `.fillna()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985-09-01    0.0\n",
       "1985-09-02    0.0\n",
       "1985-09-03    0.0\n",
       "1985-09-04    0.0\n",
       "1985-09-05    0.0\n",
       "1985-09-06    0.0\n",
       "1985-09-07    0.0\n",
       "1985-09-08    0.0\n",
       "1985-09-09    0.0\n",
       "1985-09-10    0.0\n",
       "1985-09-11    0.0\n",
       "1985-09-12    0.0\n",
       "1985-09-13    0.0\n",
       "1985-09-14    0.0\n",
       "1985-09-15    0.0\n",
       "1985-09-16    0.0\n",
       "1985-09-17    0.0\n",
       "1985-09-18    0.0\n",
       "1985-09-19    0.0\n",
       "1985-09-20    0.0\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow.loc['1985-09':'1985-09-20']\n",
    "     .fillna(0)\n",
    "     )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, some values in Jan, middle of winter and etc. might not be zero, the best way to do with missing data is the talk to a subject matter expert and determine why it is missing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987-12-30    6.0\n",
       "1987-12-31    5.0\n",
       "1988-01-01    NaN\n",
       "1988-01-02    0.0\n",
       "1988-01-03    0.0\n",
       "1988-01-04    NaN\n",
       "1988-01-05    2.0\n",
       "1988-01-06    6.0\n",
       "1988-01-07    4.0\n",
       "1988-01-08    9.0\n",
       "1988-01-09    5.0\n",
       "1988-01-10    2.0\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.loc['1987-12-30':'1988-01-10']"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas has multiple tricks for dealing with missing data\n",
    "- can use foward fill or back fill using `.ffill` and `.bfill` :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987-12-30    6.0\n",
       "1987-12-31    5.0\n",
       "1988-01-01    5.0\n",
       "1988-01-02    0.0\n",
       "1988-01-03    0.0\n",
       "1988-01-04    0.0\n",
       "1988-01-05    2.0\n",
       "1988-01-06    6.0\n",
       "1988-01-07    4.0\n",
       "1988-01-08    9.0\n",
       "1988-01-09    5.0\n",
       "1988-01-10    2.0\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.loc['1987-12-30':'1988-01-10'].ffill()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987-12-30    6.0\n",
       "1987-12-31    5.0\n",
       "1988-01-01    0.0\n",
       "1988-01-02    0.0\n",
       "1988-01-03    0.0\n",
       "1988-01-04    2.0\n",
       "1988-01-05    2.0\n",
       "1988-01-06    6.0\n",
       "1988-01-07    4.0\n",
       "1988-01-08    9.0\n",
       "1988-01-09    5.0\n",
       "1988-01-10    2.0\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.loc['1987-12-30':'1988-01-10'].bfill()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 Interpolation\n",
    "Can also use `.interpolate` , which by default does linear interpolation for missing values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987-12-30    6.0\n",
       "1987-12-31    5.0\n",
       "1988-01-01    2.5\n",
       "1988-01-02    0.0\n",
       "1988-01-03    0.0\n",
       "1988-01-04    1.0\n",
       "1988-01-05    2.0\n",
       "1988-01-06    6.0\n",
       "1988-01-07    4.0\n",
       "1988-01-08    9.0\n",
       "1988-01-09    5.0\n",
       "1988-01-10    2.0\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.loc['1987-12-30':'1988-01-10'].interpolate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Can use code below to fill in missing winter values, (if the quarter is 1 or 4) with interpolated values and the other values with zero. \n",
    "- (Because the index is datetime, we can access `.dt` attributes on it)\n",
    "- example of the `.where` method with truth table:\n",
    "\n",
    "| Winter   |      Snow      | \n",
    "|----------|:-------------:|\n",
    "| True (I) |  True (II) |\n",
    "| False (III) |   False (IV)   | \n",
    " - when it is winter, we are missing snow values, we will interpolate\n",
    "    - this is sections I and IV\n",
    "- when it is not winter and snow values are missing, we fill in with 0\n",
    "    - sections 3 and 4\n",
    "\n",
    "The `.where` method keeps values where the first parameter is `True`, so we invert the condition with `~` :\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-01    2.0\n",
       "1980-01-02    3.0\n",
       "1980-01-03    1.0\n",
       "1980-01-04    0.0\n",
       "1980-01-05    0.0\n",
       "             ... \n",
       "2019-09-03    0.0\n",
       "2019-09-04    0.0\n",
       "2019-09-05    0.0\n",
       "2019-09-06    0.0\n",
       "2019-09-07    0.0\n",
       "Name: SNOW, Length: 14160, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "winter = (snow.index.quarter == 1) | (snow.index.quarter == 4)\n",
    "(snow\n",
    "    .where(~(winter & snow.isna()), snow.interpolate())\n",
    "    .where(~(~winter & snow.isna()), 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1985-09-19    0.0\n",
       "1988-01-01    2.5\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow\n",
    "    .where(~(winter & snow.isna()), snow.interpolate())\n",
    "    .where(~(~winter & snow.isna()), 0)\n",
    "    .loc[['1985-09-19', '1988-01-01']]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1987-12-30    6.0\n",
       "1987-12-31    5.0\n",
       "1988-01-02    0.0\n",
       "1988-01-03    0.0\n",
       "1988-01-05    2.0\n",
       "1988-01-06    6.0\n",
       "1988-01-07    4.0\n",
       "1988-01-08    9.0\n",
       "1988-01-09    5.0\n",
       "1988-01-10    2.0\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow.loc['1987-12-30':'1988-01-10'].dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-01    NaN\n",
       "1980-01-02    2.0\n",
       "1980-01-03    3.0\n",
       "1980-01-04    1.0\n",
       "1980-01-05    0.0\n",
       "             ... \n",
       "2019-09-03    0.0\n",
       "2019-09-04    0.0\n",
       "2019-09-05    0.0\n",
       "2019-09-06    0.0\n",
       "2019-09-07    0.0\n",
       "Name: SNOW, Length: 14160, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.shift(1) # forward shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-01    3.0\n",
       "1980-01-02    1.0\n",
       "1980-01-03    0.0\n",
       "1980-01-04    0.0\n",
       "1980-01-05    1.0\n",
       "             ... \n",
       "2019-09-03    0.0\n",
       "2019-09-04    0.0\n",
       "2019-09-05    0.0\n",
       "2019-09-06    0.0\n",
       "2019-09-07    NaN\n",
       "Name: SNOW, Length: 14160, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "snow.shift(-1) #backward shift"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.6 Rolling Average\n",
    "To calculate the five day moving average, leverage `.shift` and do the following:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-01    NaN\n",
       "1980-01-02    NaN\n",
       "1980-01-03    NaN\n",
       "1980-01-04    NaN\n",
       "1980-01-05    1.2\n",
       "             ... \n",
       "2019-09-03    0.0\n",
       "2019-09-04    0.0\n",
       "2019-09-05    0.0\n",
       "2019-09-06    0.0\n",
       "2019-09-07    0.0\n",
       "Name: SNOW, Length: 14160, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow\n",
    "    .add(snow.shift(1))\n",
    "    .add(snow.shift(2))\n",
    "    .add(snow.shift(3))\n",
    "    .add(snow.shift(4))\n",
    "    .div(5)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-01    NaN\n",
       "1980-01-02    NaN\n",
       "1980-01-03    NaN\n",
       "1980-01-04    NaN\n",
       "1980-01-05    1.2\n",
       "             ... \n",
       "2019-09-03    0.0\n",
       "2019-09-04    0.0\n",
       "2019-09-05    0.0\n",
       "2019-09-06    0.0\n",
       "2019-09-07    0.0\n",
       "Name: SNOW, Length: 14160, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# or use .rolling:\n",
    "(snow.rolling(5).mean())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.7 Resampling\n",
    "- with dates as the index, we can use `.resample` method to aggregate valuse at different levels\n",
    "- at a high level, can group date entries by some interval (yrly, monthly, weekly) and then aggregate the values at that inteberal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-31    20.0\n",
       "1980-02-29    25.0\n",
       "1980-03-31    16.0\n",
       "1980-04-30    10.0\n",
       "1980-05-31     9.0\n",
       "              ... \n",
       "2019-05-31     5.1\n",
       "2019-06-30     0.0\n",
       "2019-07-31     0.0\n",
       "2019-08-31     0.0\n",
       "2019-09-30     0.0\n",
       "Freq: M, Name: SNOW, Length: 477, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow.resample('M').max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `'M'` string in the `.resample` call is what pandas calls an *offset alias* . This is a string that specifies a grouping frequency. \n",
    "- Using M means group all values by the end of the month\n",
    "\n",
    "If you look at the index of the result, you will see that each date is the end of the month. If you want to aggregate at the end of every two months, can use `'2M'` as the offset alias:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-31    20.0\n",
       "1980-03-31    25.0\n",
       "1980-05-31    10.0\n",
       "1980-07-31     1.0\n",
       "1980-09-30     0.0\n",
       "              ... \n",
       "2019-01-31    19.0\n",
       "2019-03-31    20.7\n",
       "2019-05-31    18.0\n",
       "2019-07-31     0.0\n",
       "2019-09-30     0.0\n",
       "Freq: 2M, Name: SNOW, Length: 239, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow.resample('2M').max())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to aggregate the maximum value for each ski season, which normally ends in May, use the following:\n",
    "- the offset alias `'A-MAY'`, indicates that we want an annual grouping (`'A'`), but ending in May of each year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-05-31    25.0\n",
       "1981-05-31    26.0\n",
       "1982-05-31    34.0\n",
       "1983-05-31    38.0\n",
       "1984-05-31    25.0\n",
       "1985-05-31    22.0\n",
       "1986-05-31    34.0\n",
       "1987-05-31    16.0\n",
       "1988-05-31    23.0\n",
       "1989-05-31    30.0\n",
       "1990-05-31    32.0\n",
       "1991-05-31    28.0\n",
       "1992-05-31    22.0\n",
       "1993-05-31    30.0\n",
       "1994-05-31    36.0\n",
       "1995-05-31    25.0\n",
       "1996-05-31    34.0\n",
       "1997-05-31    22.0\n",
       "1998-05-31    29.0\n",
       "1999-05-31    26.0\n",
       "2000-05-31    23.0\n",
       "2001-05-31    19.0\n",
       "2002-05-31    28.0\n",
       "2003-05-31    14.0\n",
       "2004-05-31    24.0\n",
       "2005-05-31    31.0\n",
       "2006-05-31    27.0\n",
       "2007-05-31    15.0\n",
       "2008-05-31    21.0\n",
       "2009-05-31    23.0\n",
       "2010-05-31    32.0\n",
       "2011-05-31    22.0\n",
       "2012-05-31    18.0\n",
       "2013-05-31    19.0\n",
       "2014-05-31    11.0\n",
       "2015-05-31    25.0\n",
       "2016-05-31    15.0\n",
       "2017-05-31    26.0\n",
       "2018-05-31    21.8\n",
       "2019-05-31    20.7\n",
       "2020-05-31     0.0\n",
       "Freq: A-MAY, Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow\n",
    "    .resample('A-MAY')\n",
    "    .max())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.8 Gatthering Aggregate Values (but keeping index)\n",
    "- instead of performing an aggregation with `.resample` we leverage the `.transform` method.\n",
    "    - works on aggregation groupsd but returns a series with the original index, mkaing it easy to do things like calculate the percentage of quarterly snowfall that fell in a day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-01    0.527009\n",
       "1980-01-02    0.790514\n",
       "1980-01-03    0.263505\n",
       "1980-01-04    0.000000\n",
       "1980-01-05    0.000000\n",
       "                ...   \n",
       "2019-09-03    0.000000\n",
       "2019-09-04    0.000000\n",
       "2019-09-05    0.000000\n",
       "2019-09-06    0.000000\n",
       "2019-09-07    0.000000\n",
       "Name: SNOW, Length: 14160, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow\n",
    "    .div(snow\n",
    "            .resample('Q')\n",
    "            .transform('sum'))\n",
    "    .mul(100)\n",
    "    .fillna(0)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To compute the percentage of a season’s snowfall that fell during each month, we could do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-10-31     2.153969\n",
       "2016-11-30     9.772637\n",
       "2016-12-31    15.715995\n",
       "2017-01-31    25.468688\n",
       "2017-02-28    21.041085\n",
       "2017-03-31     9.274033\n",
       "2017-04-30    14.738732\n",
       "2017-05-31     1.834862\n",
       "Freq: M, Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "season2017 = snow.loc['2016-10':'2017-05']\n",
    "(season2017\n",
    "    .resample('M')\n",
    "    .sum()\n",
    "    .div(season2017.sum())\n",
    "    .mul(100)\n",
    "    )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.9 Groupby Operations\n",
    "`.groupby` method that acts as a generic sort of `.resample` \n",
    "- used more on df than series\n",
    "\n",
    "example of creating a fn that will determine ski season by looking at the index with date info. Considers a season to be from Oct to Sept:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def season(idx):\n",
    "    year = idx.year\n",
    "    month =idx.month\n",
    "    return year.where((month < 10), year+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980    38.125000\n",
       "1981    41.916667\n",
       "1982    70.208333\n",
       "1983    67.291667\n",
       "1984    68.000000\n",
       "1985    44.666667\n",
       "1986    61.733333\n",
       "1987    20.258333\n",
       "1988    26.208333\n",
       "1989    35.791667\n",
       "1990    27.625000\n",
       "1991    42.058333\n",
       "1992    28.400000\n",
       "1993    56.958333\n",
       "1994    26.750000\n",
       "1995    53.750000\n",
       "1996    43.791667\n",
       "1997    46.966667\n",
       "1998    48.300000\n",
       "1999    36.308333\n",
       "2000    37.750000\n",
       "2001    39.000000\n",
       "2002    38.150000\n",
       "2003    30.450000\n",
       "2004    42.833333\n",
       "2005    39.333333\n",
       "2006    49.550000\n",
       "2007    26.641667\n",
       "2008    50.500000\n",
       "2009    39.733333\n",
       "2010    32.583333\n",
       "2011    44.483333\n",
       "2012    24.458333\n",
       "2013    30.233333\n",
       "2014    29.891667\n",
       "2015    23.691667\n",
       "2016    29.550000\n",
       "2017    43.666667\n",
       "2018    25.733333\n",
       "2019    42.041667\n",
       "Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow \n",
    "    .groupby(season)\n",
    "    .sum().div(12)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-09-30    38.125000\n",
       "1981-09-30    41.916667\n",
       "1982-09-30    70.208333\n",
       "1983-09-30    67.291667\n",
       "1984-09-30    68.000000\n",
       "1985-09-30    44.666667\n",
       "1986-09-30    61.733333\n",
       "1987-09-30    20.258333\n",
       "1988-09-30    26.208333\n",
       "1989-09-30    35.791667\n",
       "1990-09-30    27.625000\n",
       "1991-09-30    42.058333\n",
       "1992-09-30    28.400000\n",
       "1993-09-30    56.958333\n",
       "1994-09-30    26.750000\n",
       "1995-09-30    53.750000\n",
       "1996-09-30    43.791667\n",
       "1997-09-30    46.966667\n",
       "1998-09-30    48.300000\n",
       "1999-09-30    36.308333\n",
       "2000-09-30    37.750000\n",
       "2001-09-30    39.000000\n",
       "2002-09-30    38.150000\n",
       "2003-09-30    30.450000\n",
       "2004-09-30    42.833333\n",
       "2005-09-30    39.333333\n",
       "2006-09-30    49.550000\n",
       "2007-09-30    26.641667\n",
       "2008-09-30    50.500000\n",
       "2009-09-30    39.733333\n",
       "2010-09-30    32.583333\n",
       "2011-09-30    44.483333\n",
       "2012-09-30    24.458333\n",
       "2013-09-30    30.233333\n",
       "2014-09-30    29.891667\n",
       "2015-09-30    23.691667\n",
       "2016-09-30    29.550000\n",
       "2017-09-30    43.666667\n",
       "2018-09-30    25.733333\n",
       "2019-09-30    42.041667\n",
       "Freq: A-SEP, Name: SNOW, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow\n",
    "    .resample('A-SEP')\n",
    "    .sum().div(12)\n",
    "    ) #also works"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.10 Cumulative Operations\n",
    "- `.cummin`\n",
    "- `.cummax`\n",
    "- `.cumprod`\n",
    "- `.cumsum`\n",
    "\n",
    "To calculate snowfall in a season, we can combine `.cumsum` with slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2016-10-01      0.0\n",
       "2016-10-02      0.0\n",
       "2016-10-03      4.9\n",
       "2016-10-04      4.9\n",
       "2016-10-05      5.5\n",
       "              ...  \n",
       "2017-09-26    524.0\n",
       "2017-09-27    524.0\n",
       "2017-09-28    524.0\n",
       "2017-09-29    524.0\n",
       "2017-09-30    524.0\n",
       "Name: SNOW, Length: 364, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow\n",
    "    .loc['2016-10':'2017-09']\n",
    "    .cumsum())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To do calculation for every year, combine `.resample` with `.transform` and `.cumsum`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1980-01-01      2.0\n",
       "1980-01-02      5.0\n",
       "1980-01-03      6.0\n",
       "1980-01-04      6.0\n",
       "1980-01-05      6.0\n",
       "              ...  \n",
       "2019-09-03    504.5\n",
       "2019-09-04    504.5\n",
       "2019-09-05    504.5\n",
       "2019-09-06    504.5\n",
       "2019-09-07    504.5\n",
       "Name: SNOW, Length: 14160, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(snow\n",
    "    .resample('A-SEP')\n",
    "    .transform('cumsum')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
